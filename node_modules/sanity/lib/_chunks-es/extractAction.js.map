{"version":3,"file":"extractAction.js","sources":["../../src/_internal/cli/actions/schema/extractSchema.telemetry.ts","../../src/_internal/cli/actions/schema/extractAction.ts"],"sourcesContent":["import {defineTrace} from '@sanity/telemetry'\n\ninterface SchemaExtractedTraceAttrubutes {\n  schemaAllTypesCount: number\n  schemaDocumentTypesCount: number\n  schemaTypesCount: number\n\n  enforceRequiredFields: boolean\n  schemaFormat: string\n}\n\nexport const SchemaExtractedTrace = defineTrace<SchemaExtractedTraceAttrubutes>({\n  name: 'Schema Extracted',\n  version: 0,\n  description: 'Trace emitted when extracting schema',\n})\n","import {writeFile} from 'node:fs/promises'\nimport {dirname, join} from 'node:path'\nimport {fileURLToPath} from 'node:url'\nimport {Worker} from 'node:worker_threads'\n\nimport {type CliCommandArguments, type CliCommandContext} from '@sanity/cli'\nimport readPkgUp from 'read-pkg-up'\n\nimport {\n  type ExtractSchemaWorkerData,\n  type ExtractSchemaWorkerResult,\n} from '../../threads/extractSchema'\nimport {SchemaExtractedTrace} from './extractSchema.telemetry'\n\nconst __dirname = dirname(fileURLToPath(import.meta.url))\n\ninterface ExtractFlags {\n  'workspace'?: string\n  'path'?: string\n  'enforce-required-fields'?: boolean\n  'format'?: 'groq-type-nodes' | string\n}\n\nexport type SchemaValidationFormatter = (result: ExtractSchemaWorkerResult) => string\n\nexport default async function extractAction(\n  args: CliCommandArguments<ExtractFlags>,\n  {workDir, output, telemetry}: CliCommandContext,\n): Promise<void> {\n  const flags = args.extOptions\n  const formatFlag = flags.format || 'groq-type-nodes'\n  const enforceRequiredFields = flags['enforce-required-fields'] || false\n\n  const rootPkgPath = readPkgUp.sync({cwd: __dirname})?.path\n  if (!rootPkgPath) {\n    throw new Error('Could not find root directory for `sanity` package')\n  }\n\n  const workerPath = join(\n    dirname(rootPkgPath),\n    'lib',\n    '_internal',\n    'cli',\n    'threads',\n    'extractSchema.cjs',\n  )\n\n  const spinner = output\n    .spinner({})\n    .start(\n      enforceRequiredFields\n        ? 'Extracting schema, with enforced required fields'\n        : 'Extracting schema',\n    )\n\n  const trace = telemetry.trace(SchemaExtractedTrace)\n  trace.start()\n\n  const worker = new Worker(workerPath, {\n    workerData: {\n      workDir,\n      workspaceName: flags.workspace,\n      enforceRequiredFields,\n      format: formatFlag,\n    } satisfies ExtractSchemaWorkerData,\n    env: process.env,\n  })\n\n  try {\n    const {schema} = await new Promise<ExtractSchemaWorkerResult>((resolve, reject) => {\n      worker.addListener('message', resolve)\n      worker.addListener('error', reject)\n    })\n\n    trace.log({\n      schemaAllTypesCount: schema.length,\n      schemaDocumentTypesCount: schema.filter((type) => type.type === 'document').length,\n      schemaTypesCount: schema.filter((type) => type.type === 'type').length,\n      enforceRequiredFields,\n      schemaFormat: formatFlag,\n    })\n\n    const path = flags.path || join(process.cwd(), 'schema.json')\n\n    spinner.text = `Writing schema to ${path}`\n\n    await writeFile(path, `${JSON.stringify(schema, null, 2)}\\n`)\n\n    trace.complete()\n\n    spinner.succeed(\n      enforceRequiredFields\n        ? `Extracted schema to ${path} with enforced required fields`\n        : `Extracted schema to ${path}`,\n    )\n  } catch (err) {\n    trace.error(err)\n    spinner.fail(\n      enforceRequiredFields\n        ? 'Failed to extract schema, with enforced required fields'\n        : 'Failed to extract schema',\n    )\n    throw err\n  }\n}\n"],"names":["SchemaExtractedTrace","defineTrace","name","version","description","__dirname","dirname","fileURLToPath","import","url","extractAction","args","workDir","output","telemetry","flags","extOptions","formatFlag","format","enforceRequiredFields","rootPkgPath","readPkgUp","sync","cwd","path","Error","workerPath","join","spinner","start","trace","worker","Worker","workerData","workspaceName","workspace","env","process","schema","Promise","resolve","reject","addListener","log","schemaAllTypesCount","length","schemaDocumentTypesCount","filter","type","schemaTypesCount","schemaFormat","text","writeFile","JSON","stringify","complete","succeed","err","error","fail"],"mappings":";;;;;;AAWO,MAAMA,uBAAuBC,YAA4C;AAAA,EAC9EC,MAAM;AAAA,EACNC,SAAS;AAAA,EACTC,aAAa;AACf,CAAC,GCDKC,cAAYC,QAAQC,cAAcC,YAAYC,GAAG,CAAC;AAWxD,eAA8BC,cAC5BC,MACA;AAAA,EAACC;AAAAA,EAASC;AAAAA,EAAQC;AAA4B,GAC/B;AACf,QAAMC,QAAQJ,KAAKK,YACbC,aAAaF,MAAMG,UAAU,mBAC7BC,wBAAwBJ,MAAM,yBAAyB,KAAK,IAE5DK,cAAcC,UAAUC,KAAK;AAAA,IAACC,KAAKlB;AAAAA,EAAAA,CAAU,GAAGmB;AACtD,MAAI,CAACJ;AACH,UAAM,IAAIK,MAAM,oDAAoD;AAGtE,QAAMC,aAAaC,KACjBrB,QAAQc,WAAW,GACnB,OACA,aACA,OACA,WACA,mBACF,GAEMQ,UAAUf,OACbe,QAAQ,CAAA,CAAE,EACVC,MACCV,wBACI,qDACA,mBACN,GAEIW,QAAQhB,UAAUgB,MAAM9B,oBAAoB;AAClD8B,QAAMD,MAAAA;AAEN,QAAME,SAAS,IAAIC,OAAON,YAAY;AAAA,IACpCO,YAAY;AAAA,MACVrB;AAAAA,MACAsB,eAAenB,MAAMoB;AAAAA,MACrBhB;AAAAA,MACAD,QAAQD;AAAAA,IAAAA;AAAAA,IAEVmB,KAAKC,QAAQD;AAAAA,EAAAA,CACd;AAED,MAAI;AACF,UAAM;AAAA,MAACE;AAAAA,IAAAA,IAAU,MAAM,IAAIC,QAAmC,CAACC,SAASC,WAAW;AACjFV,aAAOW,YAAY,WAAWF,OAAO,GACrCT,OAAOW,YAAY,SAASD,MAAM;AAAA,IACpC,CAAC;AAEDX,UAAMa,IAAI;AAAA,MACRC,qBAAqBN,OAAOO;AAAAA,MAC5BC,0BAA0BR,OAAOS,OAAQC,UAASA,KAAKA,SAAS,UAAU,EAAEH;AAAAA,MAC5EI,kBAAkBX,OAAOS,OAAQC,UAASA,KAAKA,SAAS,MAAM,EAAEH;AAAAA,MAChE1B;AAAAA,MACA+B,cAAcjC;AAAAA,IAAAA,CACf;AAED,UAAMO,OAAOT,MAAMS,QAAQG,KAAKU,QAAQd,IAAAA,GAAO,aAAa;AAE5DK,YAAQuB,OAAO,qBAAqB3B,IAAI,IAExC,MAAM4B,UAAU5B,MAAM,GAAG6B,KAAKC,UAAUhB,QAAQ,MAAM,CAAC,CAAC;AAAA,CAAI,GAE5DR,MAAMyB,SAAAA,GAEN3B,QAAQ4B,QACNrC,wBACI,uBAAuBK,IAAI,mCAC3B,uBAAuBA,IAAI,EACjC;AAAA,EACF,SAASiC,KAAK;AACZ3B,UAAAA,MAAM4B,MAAMD,GAAG,GACf7B,QAAQ+B,KACNxC,wBACI,4DACA,0BACN,GACMsC;AAAAA,EACR;AACF;"}